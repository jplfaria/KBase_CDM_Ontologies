#!/bin/bash
# Self-contained Docker execution for order testing
# All operations contained within ontology_order_testing/ folder

set -e

# Parse arguments for nohup support
USE_NOHUP=false
ORIGINAL_ARGS=("$@")
FILTERED_ARGS=()

for arg in "$@"; do
    if [[ "$arg" == "--nohup" ]]; then
        USE_NOHUP=true
    else
        FILTERED_ARGS+=("$arg")
    fi
done

# Get the absolute path to the testing directory
TESTING_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
REPO_DIR="$(dirname "$TESTING_DIR")"

echo "üîß Order Testing Docker Runner"
echo "üìÅ Testing directory: $TESTING_DIR"
echo "üìÅ Repository directory: $REPO_DIR"

# Handle nohup execution
if [ "$USE_NOHUP" = true ]; then
    LOG_DIR="$TESTING_DIR/logs"
    mkdir -p "$LOG_DIR"
    
    TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
    LOG_FILE="$LOG_DIR/docker_run_${TIMESTAMP}.log"
    
    echo "üöÄ Running with nohup support..."
    echo "üìã Log file: $LOG_FILE"
    echo "üìä Monitor progress with: tail -f $LOG_FILE"
    echo "üîç Check if running with: ps aux | grep docker"
    echo ""
    echo "Starting background execution..."
    
    # Re-run this script without --nohup in background
    nohup "$0" "${FILTERED_ARGS[@]}" > "$LOG_FILE" 2>&1 &
    
    echo "‚úÖ Background process started with PID: $!"
    echo "üìã Log file: $LOG_FILE"
    echo ""
    echo "Commands to monitor:"
    echo "  tail -f $LOG_FILE                    # Follow log output"
    echo "  grep -E '(‚úÖ|‚ùå|üß™|üìä)' $LOG_FILE    # Show status updates"
    echo "  ps aux | grep docker                # Check if still running"
    echo ""
    exit 0
fi

# Check if we have the required files
if [ ! -f "$TESTING_DIR/local_env/.env.local" ]; then
    echo "‚ùå Missing: $TESTING_DIR/local_env/.env.local"
    exit 1
fi

if [ ! -f "$TESTING_DIR/ontologies_source_full.txt" ]; then
    echo "‚ùå Missing: $TESTING_DIR/ontologies_source_full.txt"
    exit 1
fi

# Function to run Docker with proper mounts
run_docker() {
    local script_path="$1"
    local description="$2"
    
    echo ""
    echo "üöÄ Running: $description"
    echo "üìã Script: $script_path"
    
    # Export host user ID for Docker (UID might be readonly, so check first)
    if [ -z "$UID" ] || [ "$UID" = "" ]; then
        export UID=$(id -u)
    fi
    export GID=$(id -g)
    
    # Load environment variables from local env file  
    source "$TESTING_DIR/local_env/.env.local"
    
    # Run as root to avoid permission issues with different user IDs across systems
    # (Dockerfile has hardcoded user 502, but host systems vary widely)
    docker compose -f "$REPO_DIR/docker-compose.yml" -f "$TESTING_DIR/docker-compose.override.yml" run --rm --user root \
        -v "$TESTING_DIR:/home/ontology/workspace/testing" \
        -w "/home/ontology/workspace/testing" \
        cdm-ontologies \
        python "$script_path"
}

# Function to run with custom working directory
run_docker_custom() {
    local command="$1"
    local description="$2"
    
    echo ""
    echo "üöÄ Running: $description"
    echo "üìã Command: $command"
    
    # Export host user ID for Docker (UID might be readonly, so check first)
    if [ -z "$UID" ] || [ "$UID" = "" ]; then
        export UID=$(id -u)
    fi
    export GID=$(id -g)
    
    # Load environment variables from local env file  
    source "$TESTING_DIR/local_env/.env.local"
    
    # Run as root to avoid permission issues with different user IDs across systems
    # (Dockerfile has hardcoded user 502, but host systems vary widely)
    docker compose -f "$REPO_DIR/docker-compose.yml" -f "$TESTING_DIR/docker-compose.override.yml" run --rm --user root \
        -v "$TESTING_DIR:/home/ontology/workspace/testing" \
        -w "/home/ontology/workspace/testing" \
        cdm-ontologies \
        $command
}

# Main execution
case "${1:-all}" in
    "download")
        echo "üì• Downloading all ontologies..."
        run_docker "scripts/download_ontologies.py" "Download all ontologies"
        ;;
    
    "pseudo-base")
        echo "üîß Creating pseudo-base versions..."
        run_docker "scripts/create_pseudo_base_local.py" "Create pseudo-base versions"
        ;;
    
    "test-orders")
        echo "üß™ Testing merge orders..."
        run_docker "test_merge_orders.py" "Test different merge orders"
        ;;
    
    "enhanced")
        echo "üî¨ Running enhanced analysis (24 ontologies)..."
        run_docker "enhanced_order_analysis.py" "Enhanced 24-ontology analysis"
        ;;
    
    "permutations")
        echo "üß¨ Running permutation tests (4 ontologies)..."
        run_docker "test_permutations_4onto.py" "4-ontology permutation tests"
        ;;
    
    "summary")
        echo "üìã Generating summary report..."
        run_docker "generate_summary.py" "Generate summary report"
        ;;
    
    "compare")
        echo "üîç Comparing merge results..."
        run_docker "compare_merges.py" "Compare merge results"
        ;;
    
    "analyze")
        echo "üìä Analyzing annotations..."
        run_docker "analyze_annotations.py" "Analyze term annotations"
        ;;
    
    "shell")
        echo "üêö Opening interactive shell..."
        run_docker_custom "bash" "Interactive shell"
        ;;
    
    "all")
        echo "üéØ Running complete testing workflow..."
        
        # Step 1: Download ontologies
        echo ""
        echo "=" * 60
        echo "STEP 1: Download ontologies"
        echo "=" * 60
        run_docker "scripts/download_ontologies.py" "Download all ontologies"
        
        # Step 2: Create pseudo-base versions
        echo ""
        echo "=" * 60
        echo "STEP 2: Create pseudo-base versions"
        echo "=" * 60
        run_docker "scripts/create_pseudo_base_local.py" "Create pseudo-base versions"
        
        # Step 3: Enhanced analysis (24 ontologies)
        echo ""
        echo "=" * 60
        echo "STEP 3: Enhanced analysis (24 ontologies)"
        echo "=" * 60
        run_docker "enhanced_order_analysis.py" "Enhanced 24-ontology analysis"
        
        # Step 4: Permutation tests (4 ontologies)
        echo ""
        echo "=" * 60
        echo "STEP 4: Permutation tests (4 ontologies)"
        echo "=" * 60
        run_docker "test_permutations_4onto.py" "4-ontology permutation tests"
        
        # Step 5: Generate summary report
        echo ""
        echo "=" * 60
        echo "STEP 5: Generate summary report"
        echo "=" * 60
        run_docker "generate_summary.py" "Generate summary report"
        
        echo ""
        echo "üéâ Complete testing workflow finished!"
        echo "üìã Check results/ directory for outputs"
        ;;
    
    *)
        echo "Usage: $0 [download|pseudo-base|test-orders|enhanced|permutations|summary|compare|analyze|shell|all] [--nohup]"
        echo ""
        echo "Commands:"
        echo "  download     - Download all 23 ontologies"
        echo "  pseudo-base  - Create pseudo-base versions of non-base ontologies"
        echo "  test-orders  - Test different merge orders (legacy)"
        echo "  enhanced     - Enhanced 24-ontology analysis with term tracking"
        echo "  permutations - Exhaustive 4-ontology permutation testing"
        echo "  summary      - Generate comprehensive summary report"
        echo "  compare      - Compare merge results (legacy)"
        echo "  analyze      - Analyze term annotations (legacy)"
        echo "  shell        - Open interactive shell"
        echo "  all          - Run complete workflow (default)"
        echo ""
        echo "Options:"
        echo "  --nohup      - Run in background with nohup (survives SSH disconnection)"
        echo ""
        echo "Examples:"
        echo "  $0 all                    # Run complete workflow in foreground"
        echo "  $0 all --nohup           # Run complete workflow in background"
        echo "  $0 enhanced --nohup      # Run enhanced analysis in background"
        exit 1
        ;;
esac

echo ""
echo "‚úÖ Task completed successfully!"